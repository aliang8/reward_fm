Running LIBERO regular dataset evaluations at Wed Aug 20 18:03:53 PDT 2025
=== Evaluating subset: libero_10 ===
Start time: Wed Aug 20 18:03:53 PDT 2025
Applied config override: evaluation.eval_dataset_path = abraranwar/libero_rfm
Applied config override: evaluation.eval_dataset_subsets = [libero_10]
Setting up evaluation data generator on rank 0...
Loading 2 evaluation datasets with corresponding subsets
  Dataset 1: abraranwar/libero_rfm -> libero_10
  Dataset 2: ykorkmaz/libero_failure_rfm -> libero_10_failure
Found preprocessed evaluation cache at ./processed_datasets/eval_cache, loading...
Loaded 997 trajectory indices from preprocessed evaluation cache
Successfully loaded preprocessed evaluation cache with 997 trajectory indices
No preference dataset provided, will use random sampling for preferences
No similarity dataset provided, will use random sampling for similarities
DataGenerator initialized with 997 total trajectories
  Robot trajectories: 997
  Human trajectories: 0
  Tasks: 10
  Quality labels: 2
  Data sources: 2
Evaluation data generator initialized on rank 0
Evaluating (all prefs):   0%|          | 0/42 [00:00<?, ?it/s]Evaluating (all prefs):   2%|▏         | 1/42 [00:15<10:25, 15.27s/it]Evaluating (all prefs):   5%|▍         | 2/42 [00:30<09:58, 14.97s/it]Evaluating (all prefs):   7%|▋         | 3/42 [00:44<09:36, 14.79s/it]Evaluating (all prefs):  10%|▉         | 4/42 [00:59<09:17, 14.67s/it]Evaluating (all prefs):  12%|█▏        | 5/42 [01:13<09:04, 14.73s/it]Evaluating (all prefs):  14%|█▍        | 6/42 [01:33<09:43, 16.22s/it]Evaluating (all prefs):  17%|█▋        | 7/42 [01:50<09:36, 16.48s/it]Evaluating (all prefs):  19%|█▉        | 8/42 [02:24<12:32, 22.14s/it]Evaluating (all prefs):  21%|██▏       | 9/42 [02:43<11:36, 21.10s/it]Evaluating (all prefs):  24%|██▍       | 10/42 [03:02<10:59, 20.60s/it]Evaluating (all prefs):  26%|██▌       | 11/42 [03:23<10:38, 20.58s/it]Evaluating (all prefs):  29%|██▊       | 12/42 [03:40<09:50, 19.67s/it]Evaluating (all prefs):  31%|███       | 13/42 [04:03<09:57, 20.60s/it]Evaluating (all prefs):  33%|███▎      | 14/42 [04:28<10:18, 22.08s/it]Evaluating (all prefs):  36%|███▌      | 15/42 [04:48<09:39, 21.46s/it]Evaluating (all prefs):  38%|███▊      | 16/42 [05:04<08:32, 19.70s/it]Evaluating (all prefs):  40%|████      | 17/42 [06:25<15:55, 38.23s/it]Evaluating (all prefs):  43%|████▎     | 18/42 [06:41<12:34, 31.43s/it]Evaluating (all prefs):  45%|████▌     | 19/42 [07:40<15:10, 39.58s/it]Evaluating (all prefs):  48%|████▊     | 20/42 [07:54<11:45, 32.08s/it]Evaluating (all prefs):  50%|█████     | 21/42 [08:32<11:50, 33.86s/it]Evaluating (all prefs):  52%|█████▏    | 22/42 [08:47<09:24, 28.23s/it]Evaluating (all prefs):  55%|█████▍    | 23/42 [09:03<07:46, 24.53s/it]Evaluating (all prefs):  55%|█████▍    | 23/42 [11:03<09:08, 28.86s/it]
batch metrics: {'eval_accuracy': 0.8333333333333334, 'eval_reward_diff': None, 'eval_avg_reward_chosen': None, 'eval_avg_reward_rejected': None, 'demo_reward_alignment': None}
batch metrics: {'eval_accuracy': 0.6666666666666666, 'eval_reward_diff': None, 'eval_avg_reward_chosen': None, 'eval_avg_reward_rejected': None, 'demo_reward_alignment': None}
batch metrics: {'eval_accuracy': 1.0, 'eval_reward_diff': None, 'eval_avg_reward_chosen': None, 'eval_avg_reward_rejected': None, 'demo_reward_alignment': None}
batch metrics: {'eval_accuracy': 0.6666666666666666, 'eval_reward_diff': None, 'eval_avg_reward_chosen': None, 'eval_avg_reward_rejected': None, 'demo_reward_alignment': None}
batch metrics: {'eval_accuracy': 1.0, 'eval_reward_diff': None, 'eval_avg_reward_chosen': None, 'eval_avg_reward_rejected': None, 'demo_reward_alignment': None}
batch metrics: {'eval_accuracy': 1.0, 'eval_reward_diff': None, 'eval_avg_reward_chosen': None, 'eval_avg_reward_rejected': None, 'demo_reward_alignment': None}
batch metrics: {'eval_accuracy': 1.0, 'eval_reward_diff': None, 'eval_avg_reward_chosen': None, 'eval_avg_reward_rejected': None, 'demo_reward_alignment': None}
batch metrics: {'eval_accuracy': 1.0, 'eval_reward_diff': None, 'eval_avg_reward_chosen': None, 'eval_avg_reward_rejected': None, 'demo_reward_alignment': None}
batch metrics: {'eval_accuracy': 0.75, 'eval_reward_diff': None, 'eval_avg_reward_chosen': None, 'eval_avg_reward_rejected': None, 'demo_reward_alignment': None}
batch metrics: {'eval_accuracy': 0.5833333333333334, 'eval_reward_diff': None, 'eval_avg_reward_chosen': None, 'eval_avg_reward_rejected': None, 'demo_reward_alignment': None}
batch metrics: {'eval_accuracy': 0.75, 'eval_reward_diff': None, 'eval_avg_reward_chosen': None, 'eval_avg_reward_rejected': None, 'demo_reward_alignment': None}
batch metrics: {'eval_accuracy': 0.8333333333333334, 'eval_reward_diff': None, 'eval_avg_reward_chosen': None, 'eval_avg_reward_rejected': None, 'demo_reward_alignment': None}
batch metrics: {'eval_accuracy': 0.5, 'eval_reward_diff': None, 'eval_avg_reward_chosen': None, 'eval_avg_reward_rejected': None, 'demo_reward_alignment': None}
batch metrics: {'eval_accuracy': 0.25, 'eval_reward_diff': None, 'eval_avg_reward_chosen': None, 'eval_avg_reward_rejected': None, 'demo_reward_alignment': None}
batch metrics: {'eval_accuracy': 0.25, 'eval_reward_diff': None, 'eval_avg_reward_chosen': None, 'eval_avg_reward_rejected': None, 'demo_reward_alignment': None}
batch metrics: {'eval_accuracy': 0.16666666666666666, 'eval_reward_diff': None, 'eval_avg_reward_chosen': None, 'eval_avg_reward_rejected': None, 'demo_reward_alignment': None}
batch metrics: {'eval_accuracy': 0.16666666666666666, 'eval_reward_diff': None, 'eval_avg_reward_chosen': None, 'eval_avg_reward_rejected': None, 'demo_reward_alignment': None}
batch metrics: {'eval_accuracy': 0.3333333333333333, 'eval_reward_diff': None, 'eval_avg_reward_chosen': None, 'eval_avg_reward_rejected': None, 'demo_reward_alignment': None}
batch metrics: {'eval_accuracy': 0.3333333333333333, 'eval_reward_diff': None, 'eval_avg_reward_chosen': None, 'eval_avg_reward_rejected': None, 'demo_reward_alignment': None}
batch metrics: {'eval_accuracy': 0.25, 'eval_reward_diff': None, 'eval_avg_reward_chosen': None, 'eval_avg_reward_rejected': None, 'demo_reward_alignment': None}
batch metrics: {'eval_accuracy': 0.3333333333333333, 'eval_reward_diff': None, 'eval_avg_reward_chosen': None, 'eval_avg_reward_rejected': None, 'demo_reward_alignment': None}
batch metrics: {'eval_accuracy': 0.5, 'eval_reward_diff': None, 'eval_avg_reward_chosen': None, 'eval_avg_reward_rejected': None, 'demo_reward_alignment': None}
batch metrics: {'eval_accuracy': 0.8333333333333334, 'eval_reward_diff': None, 'eval_avg_reward_chosen': None, 'eval_avg_reward_rejected': None, 'demo_reward_alignment': None}
Traceback (most recent call last):
  File "/Users/kaushiksid/projs/rlplus/reward_fm/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/Users/kaushiksid/projs/rlplus/reward_fm/.venv/lib/python3.11/site-packages/urllib3/connection.py", line 565, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/kaushiksid/.local/share/uv/python/cpython-3.11.10-macos-aarch64-none/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/Users/kaushiksid/.local/share/uv/python/cpython-3.11.10-macos-aarch64-none/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/Users/kaushiksid/.local/share/uv/python/cpython-3.11.10-macos-aarch64-none/lib/python3.11/http/client.py", line 286, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/kaushiksid/.local/share/uv/python/cpython-3.11.10-macos-aarch64-none/lib/python3.11/socket.py", line 718, in readinto
    return self._sock.recv_into(b)
           ^^^^^^^^^^^^^^^^^^^^^^^
TimeoutError: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/kaushiksid/projs/rlplus/reward_fm/.venv/lib/python3.11/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/Users/kaushiksid/projs/rlplus/reward_fm/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/Users/kaushiksid/projs/rlplus/reward_fm/.venv/lib/python3.11/site-packages/urllib3/util/retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/kaushiksid/projs/rlplus/reward_fm/.venv/lib/python3.11/site-packages/urllib3/util/util.py", line 39, in reraise
    raise value
  File "/Users/kaushiksid/projs/rlplus/reward_fm/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/Users/kaushiksid/projs/rlplus/reward_fm/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py", line 536, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
  File "/Users/kaushiksid/projs/rlplus/reward_fm/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py", line 367, in _raise_timeout
    raise ReadTimeoutError(
urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='localhost', port=8002): Read timed out. (read timeout=120.0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/kaushiksid/projs/rlplus/reward_fm/evals/run_model_eval.py", line 318, in <module>
    main()
  File "/Users/kaushiksid/projs/rlplus/reward_fm/evals/run_model_eval.py", line 275, in main
    results = iter_eval_all_preferences(cfg=cfg, server_url=args.server_url, batch_size=args.batch_size)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/kaushiksid/projs/rlplus/reward_fm/evals/run_model_eval.py", line 228, in iter_eval_all_preferences
    results.append(_evaluate_samples(server_url, batch))
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/kaushiksid/projs/rlplus/reward_fm/evals/run_model_eval.py", line 104, in _evaluate_samples
    resp = post_batch(server_url, payload)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/kaushiksid/projs/rlplus/reward_fm/evals/eval_utils.py", line 253, in post_batch
    resp = requests.post(url.rstrip("/") + "/evaluate_batch", json=payload, timeout=timeout_s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/kaushiksid/projs/rlplus/reward_fm/.venv/lib/python3.11/site-packages/requests/api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/kaushiksid/projs/rlplus/reward_fm/.venv/lib/python3.11/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/kaushiksid/projs/rlplus/reward_fm/.venv/lib/python3.11/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/kaushiksid/projs/rlplus/reward_fm/.venv/lib/python3.11/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/kaushiksid/projs/rlplus/reward_fm/.venv/lib/python3.11/site-packages/requests/adapters.py", line 713, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='localhost', port=8002): Read timed out. (read timeout=120.0)
End time: Wed Aug 20 18:15:12 PDT 2025
=== Completed subset: libero_10 ===

Completed all LIBERO regular dataset evaluations at Wed Aug 20 18:15:12 PDT 2025

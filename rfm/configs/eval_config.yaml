# Evaluation Configuration for RFM
# This config is used specifically for evaluation runs

# Model path to load training config from
model_path: "aliangdw/rfm_prefprog_v4"  # Path to the trained model checkpoint (will load training_config.yaml from here)

# GPU Pool settings
num_gpus: 4  # Number of GPUs to use (null for all available)
max_workers: null  # Max worker threads (null for auto, typically same as num_gpus)

# Evaluation parameters
eval_subset_size: 1000  # Number of samples to evaluate
batch_size: 4  # Batch size for evaluation
num_batches: -1  # Number of batches to evaluate (-1 for full dataset)
server_url: "0.0.0.0"  # Evaluation server URL
server_port: 8000  # Evaluation server port
log_dir: "./eval_logs"  # Directory to save evaluation results

# Data settings (reused from experiment_configs.DataConfig)
data:
  # Evaluation dataset settings
  # success/failure
  # eval_datasets: ["abraranwar/libero_rfm", "ykorkmaz/libero_failure_rfm"]
  # eval_subsets: ["libero256_10", "libero_10_failure"]
  # reward alignment
  # eval_datasets: ["HenryZhang/metaworld_rewind_rfm_eval"]
  # eval_subsets: ["metaworld_rewind_eval"]
  # reward alignment
  # eval_datasets: ["abraranwar/libero_rfm"]
  # eval_subsets: ["libero256_10"]
  # policy ranking
  eval_datasets: ["aliangdw/metaworld_rfm"]
  eval_subsets: ["metaworld"]
  
  eval_subset_size: 1000  # Number of evaluation examples
  
  # For preprocessing
  max_frames_for_preprocessing: 64

  # Video processing settings
  max_frames: 16
  
  dataset_type: reward_alignment  # reward_alignment, success_failure, policy_ranking, confusion_matrix, wrong_task, default

  # extra settings for eval datasets 
  num_bins: 3
  fps: 10

  max_trajectories: 1000
# Evaluation Configuration for RFM
# This config is used specifically for evaluation runs

# Model path to load training config from
# model_path: "aliangdw/rfm_prefprog_v4"  # Path to the trained model checkpoint (will load training_config.yaml from here)
# model_path: "aliangdw/rewind-libero-mw-pp-balanced"
# model_path: "aliangdw/rewind-base-mw-only"
model_path: "aliangdw/rewind-pp"

# GPU Pool settings
num_gpus: 1  # Number of GPUs to use (null for all available)
max_workers: null  # Max worker threads (null for auto, typically same as num_gpus)

# Evaluation parameters
eval_subset_size: 1000  # Number of samples to evaluate
batch_size: 4  # Batch size for evaluation
num_batches: -1  # Number of batches to evaluate (-1 for full dataset)
server_url: "0.0.0.0"  # Evaluation server URL
server_port: 8000  # Evaluation server port
log_dir: "./eval_logs"  # Directory to save evaluation results


# =====================================================================================
# Custom Evaluation Configuration
# =====================================================================================
custom_eval:
  # this section is for adding additional evals like policy ranking, confusion matrix, and alignment etc
  # during training 
  eval_types: ["policy_ranking", "confusion_matrix", "reward_alignment"]
  policy_ranking: 
    - ["aliangdw/metaworld_rfm", "metaworld"]
  confusion_matrix: 
    - ["aliangdw/metaworld_rfm", "metaworld"]
  reward_alignment: 
    - ["HenryZhang/metaworld_rewind_rfm_eval", "metaworld_rewind_eval"]

data:
  load_embeddings: true
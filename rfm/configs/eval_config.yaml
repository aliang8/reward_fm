# Evaluation Configuration for RFM
# This config is used specifically for evaluation runs

# Model path to load training config from
model_path: "aliangdw/rfm_v1"  # Path to the trained model checkpoint (will load training_config.yaml from here)

# Evaluation parameters
eval_subset_size: 1000  # Number of samples to evaluate
batch_size: 16  # Batch size for evaluation
num_batches: 20  # Number of batches to evaluate (-1 for full dataset)
server_url: "0.0.0.0"  # Evaluation server URL
server_port: 8000  # Evaluation server port
log_dir: "./eval_logs"  # Directory to save evaluation results

# Data settings (reused from experiment_configs.DataConfig)
data:
  # Evaluation dataset settings
  eval_datasets: ["abraranwar/libero_rfm"]
  eval_subsets: ["libero_object"]
  # eval_datasets: ["aliangdw/metaworld_rfm"]
  # eval_subsets: ["metaworld"]
  eval_subset_size: 1000  # Number of evaluation examples
  
  # Video processing settings
  max_frames: 8  # Maximum frames per trajectory
  video_frame_sampling: "uniform"  # "uniform", "random", "first", "middle"
  resized_height: 128  # Height to resize images/videos to
  resized_width: 128  # Width to resize images/videos to
  
  # Data generation settings
  preference_ratio: 1.0  # Ratio of preference prediction samples
  dataset_preference_ratio: 0.7  # Ratio of preferences from dataset vs generated
  preference_strategy_ratio: [0.8, 0.1, 0.1]  # [rewind_same_task, suboptimal_same_task, different_task]
  shuffle: true
  seed: 42
  num_proc: 1  # Number of processes for dataset processing
  force_reprocess: false  # Force reprocessing of dataset even if cached version exists
  
  # Data loading settings
  dataloader_pin_memory: false
  dataloader_num_workers: 0
  dataset_type: video_binned

  # extra settings for eval datasets 
  num_bins: 10
  fps: 10
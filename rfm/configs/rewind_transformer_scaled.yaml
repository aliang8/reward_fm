# @package _global_

# ReWIND Transformer Configuration
# Inherits from config.yaml and overrides specific settings
defaults:
  - config 
  - _self_

trainer_cls: rewind_transformer

# =====================================================================================
# Model Configuration
# =====================================================================================
model:
  base_model_id: rewind_transformer  # custom transformer model

  # set rewind specific parameters
  rewind:
    video_feature_dim: 768
    text_feature_dim: 384
    hidden_dim: 1024
    num_layers: 32
    num_attention_heads: 16
    dropout: 0.1  
    max_len: 16
    causal_mask: false
    use_per_frame_progress_token: false
    progress_loss_type: discrete
    progress_discrete_bins: 32

training:
  gradient_checkpointing: true  # Enable for deep model memory efficiency

  bf16: false
  fp16: true

  per_device_train_batch_size: 1024
  per_device_eval_batch_size: 512
  learning_rate: 3e-5  # Lower LR for deep 32-layer model
  weight_decay: 0.01
  warmup_ratio: 0.05  # Longer warmup for stable deep model training
  
  eval_steps: 200
  custom_eval_steps: 200
  max_steps: 20000

# Loss weights for multi-task balancing
loss:
  preference_loss_weight: 1.0
  progress_loss_weight: 1.0

data:  
  load_embeddings: true